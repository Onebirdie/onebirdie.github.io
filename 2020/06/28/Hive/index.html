<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Hive | Hi...</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="一、Hive概述Hive(蜜蜂)设计目的是让精通SQL技能单Java编程技能相对较弱的分析师能过对存放在HDFS中的大规模数据集执行查询。很多组织把它作用为一个通用的、可伸缩的数据处理平台。 1234567Hive-info：	1.构建在Hadoop上的数据仓库框架(HDFS存储数据，YARN资源管理，MapReduce负责数据处理)	2.使用HiveQL进行数据执行查询。它把SQL查询转换为一系">
<meta property="og:type" content="article">
<meta property="og:title" content="Hive">
<meta property="og:url" content="http://example.com/2020/06/28/Hive/index.html">
<meta property="og:site_name" content="Hi...">
<meta property="og:description" content="一、Hive概述Hive(蜜蜂)设计目的是让精通SQL技能单Java编程技能相对较弱的分析师能过对存放在HDFS中的大规模数据集执行查询。很多组织把它作用为一个通用的、可伸缩的数据处理平台。 1234567Hive-info：	1.构建在Hadoop上的数据仓库框架(HDFS存储数据，YARN资源管理，MapReduce负责数据处理)	2.使用HiveQL进行数据执行查询。它把SQL查询转换为一系">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/2020/06/28/images/2020-01-12_123837.png">
<meta property="og:image" content="http://example.com/2020/06/28/images/2020-01-13_091250.png">
<meta property="article:published_time" content="2020-06-27T16:00:00.000Z">
<meta property="article:modified_time" content="2022-04-14T12:58:12.178Z">
<meta property="article:author" content="Onebirdie">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2020/06/28/images/2020-01-12_123837.png">
  
    <link rel="alternate" href="/atom.xml" title="Hi..." type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/images/favicon.ico">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
<meta name="generator" content="Hexo 5.4.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hi...</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-Hive" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2020/06/28/Hive/" class="article-date">
  <time class="dt-published" datetime="2020-06-27T16:00:00.000Z" itemprop="datePublished">2020-06-28</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      Hive
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="一、Hive概述"><a href="#一、Hive概述" class="headerlink" title="一、Hive概述"></a>一、Hive概述</h2><p>Hive(蜜蜂)设计目的是让精通<code>SQL</code>技能单Java编程技能相对较弱的分析师能过对存放在<code>HDFS</code>中的<code>大规模数据集</code>执行查询。很多组织把它作用为一个通用的、可伸缩的数据处理平台。</p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Hive-info：</span><br><span class="line"><span class="code">	1.构建在Hadoop上的数据仓库框架(HDFS存储数据，YARN资源管理，MapReduce负责数据处理)</span></span><br><span class="line"><span class="code">	2.使用HiveQL进行数据执行查询。它把SQL查询转换为一系列在Hadoop集群上运行的作业（MapReduce程序）。</span></span><br><span class="line"><span class="code">	  2.1.Hive把数据组织为表，通过这种方式为存储在HDFS上的数据赋予结构</span></span><br><span class="line"><span class="code">      2.2.元数据（如表模式）存在在metastore数据库中</span></span><br><span class="line"><span class="code">	3.对数据进行ETL-（提取，转化，加载）</span></span><br><span class="line"><span class="code">	4.Hive一般在工作站上运行</span></span><br></pre></td></tr></table></figure>

<p>Jeff Hammerbacher把<code>信息平台</code>描述为<code>企业摄取</code>，<code>处理</code>，<code>生成信息</code>的<code>行为</code>与<code>帮助加速从经验数据中学习</code>的<code>中心</code>。</p>
<p>在<code>Facebook</code>，Jeff团队所构建的信息平台是应<code>Facebook</code>每天产生的<code>海量</code>新型社会网络<code>数据</code>进行<code>管理</code>和（机器）学习的需求而<code>产生</code>和<code>发展</code>的。但是并不适合用来开发复杂的机器学习算法。</p>
<blockquote>
<p>Hive可以通过<code>ODBC</code>与商业智能工具进行进行集成</p>
</blockquote>
<h3 id="1-1Hive架构"><a href="#1-1Hive架构" class="headerlink" title="1.1Hive架构"></a>1.1Hive架构</h3><p>Hive提供了一个SQL命令的操作接口，允许用户可以使用类似SQL的Hive的Query Language执行一些离线的SQL分析。但是Hive和传统的数据库不同，Hive只是构建在Hadoop的MapReduce之上的SQL解析工具，并不参与数据的管理和存储，Hive中所有的数据都是在运行任务的时候才会真正的加载。  </p>
<p><img src="../images/2020-01-12_123837.png"></p>
<p>Hive体系图</p>
<p><img src="../images/2020-01-13_091250.png"></p>
<h2 id="二、安装Hive"><a href="#二、安装Hive" class="headerlink" title="二、安装Hive"></a>二、安装Hive</h2><h3 id="2-1-环境的准备"><a href="#2-1-环境的准备" class="headerlink" title="2.1.环境的准备"></a>2.1.环境的准备</h3><ol>
<li><p>HDFS</p>
</li>
<li><p>yarn</p>
</li>
<li><p>MySql</p>
<blockquote>
<p>*MySql数据库的编码格式必须是Latin1编码,HADOOP_HOME配置用于感知用户的Hadoop计算集群的位置和规模。</p>
</blockquote>
</li>
</ol>
<h3 id="2-2-安装Hive"><a href="#2-2-安装Hive" class="headerlink" title="2.2.安装Hive"></a>2.2.安装Hive</h3><ol>
<li><p>解压hive安装包（安装包：<a target="_blank" rel="noopener" href="http://hive.apache.org)/">http://hive.apache.org）</a></p>
</li>
<li><p>hive目录中conf目录下创建hive-site.xml</p>
<ol>
<li><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!--配置hive-site.xml--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot;?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!--JDBC连接字符串--&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:mysql://CentOS:3306/hive?createDatabaseIfNotExist=true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!--JDBC的driver--&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">		**准备一个与安装的MySql相同的驱动jar</span></span><br><span class="line"><span class="comment">		com.mysql.jdbc.Driver:就是驱动类的全限定名</span></span><br><span class="line"><span class="comment">		准备的jar包拷贝到hive目录下的lib目录中</span></span><br><span class="line"><span class="comment">	--&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>com.mysql.jdbc.Driver<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!--连接用户--&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>root<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!--连接用户密码--&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>root<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
</ol>
</li>
<li><p>配置HIVE_HOME环境变量</p>
<ol>
<li><p>```shell<br>#局部变量(用户目录中的bashrc)|全局变量(/etc/profile)<br>export HIVE_HOME=hive目录的路径<br>#配置PATH方便使用hive的二进制脚本 挂载到PATH上  :$HIVE_HOME/bin</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">4. 启动Hive</span><br><span class="line"></span><br><span class="line">   1. 单用户模式</span><br><span class="line"></span><br><span class="line">      1. ```shell</span><br><span class="line">         [root@CentOS ~]# hive  </span><br><span class="line">         </span><br><span class="line">         Logging initialized using configuration in jar:file:/usr/apache-hive-1.2.2-bin/lib/hive-common-1.2.2.jar!/hive-log4j.properties</span><br><span class="line">         Logging initialized using configuration in jar:file:/usr/apache-hive-1.2.2-bin/lib/hive-common-1.2.2.jar!/hive-log4j.properties</span><br><span class="line">         hive&gt; show databases;</span><br><span class="line">         OK</span><br><span class="line">         default</span><br><span class="line">         Time taken: 1.742 seconds, Fetched: 1 row(s)</span><br><span class="line">         hive&gt; create database baizhi;</span><br><span class="line">         OK</span><br><span class="line">         Time taken: 0.363 seconds</span><br><span class="line">         hive&gt; show databases;</span><br><span class="line">         OK</span><br><span class="line">         baizhi</span><br><span class="line">         default</span><br><span class="line">         Time taken: 0.039 seconds, Fetched: 2 row(s)</span><br><span class="line">         #启动成功之后会在MySql数据库中创建一个hive数据库，并创建29基础表</span><br></pre></td></tr></table></figure></li>
<li><p>多用户模式</p>
<ol>
<li>```shell<br>[root@CentOS ~]# hiveserver2 &gt;/dev/null 2&gt;&amp;1 &amp;  # 后台启动服务<br>[1] 8772<br>[root@CentOS ~]# beeline -u jdbc:hive2://CentOS:10000 -n root<br>Connecting to jdbc:hive2://CentOS:10000<br>Connected to: Apache Hive (version 1.2.2)<br>Driver: Hive JDBC (version 1.2.2)<br>Transaction isolation: TRANSACTION_REPEATABLE_READ<br>Beeline version 1.2.2 by Apache Hive<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">## 三、Hive使用学习</span><br><span class="line"></span><br><span class="line">### 3.1.HiveQL</span><br><span class="line"></span><br><span class="line">Hive的SQL”方言”称为HiveQL，是SQL-92，MySQL和Oracle SQL语言的混合体。</span><br><span class="line"></span><br><span class="line">#### 3.1.1数据类型</span><br><span class="line"></span><br><span class="line">##### 	1.原始类型</span><br><span class="line"></span><br><span class="line">| 类型      | 描述                              | 字面量示例   |</span><br><span class="line">| --------- | --------------------------------- | ------------ |</span><br><span class="line">| BOOLEAN   | 布尔值，可选值true/false          | true         |</span><br><span class="line">| TINYINT   | 1字节的有符号整数 -128~127        | 1Y           |</span><br><span class="line">| SMALLINT  | 2个字节的有符号整数，-32768~32767 | 1S           |</span><br><span class="line">| INT       | 4个字节的带符号整数               | 1            |</span><br><span class="line">| BIGINT    | 8字节带符号整数                   | 1L           |</span><br><span class="line">| FLOAT     | 4字节单精度浮点数                 |1.0              |</span><br><span class="line">| OUBLE     | 8字节双精度浮点数                 | 1.0          |</span><br><span class="line">| DEICIMAL  | 任意精度的带符号小数              | 1.0          |</span><br><span class="line">| STRING    | 字符串，变长                      | &quot;Abc&quot;        |</span><br><span class="line">| VARCHAR   | 变长字符串                        | &quot;Aac&quot;        |</span><br><span class="line">| CHAR      | 固定长度字符串                    | “a”,’b’      |</span><br><span class="line">| BINARY    | 字节数组                          | 不支持 |</span><br><span class="line">| TIMESTAMP | 时间戳，纳秒精度                  | 122327493795 |</span><br><span class="line">| DATE      | 日期                              | ‘2020-01-01  |</span><br><span class="line"></span><br><span class="line">##### 2.复杂数据类型</span><br><span class="line"></span><br><span class="line">| 类型   | 描述                                           | 字面量示例                                                   |</span><br><span class="line">| ------ | ---------------------------------------------- | ------------------------------------------------------------ |</span><br><span class="line">| ARRAY  | 有序的的同类型的集合                           | array(1,2)                                                   |</span><br><span class="line">| MAP    | key-value,key必须为原始类型，value可以任意类型 | map(‘a’,1,’b’,2)                                             |</span><br><span class="line">| STRUCT | 字段集合,类型可以不同                          | struct(‘1’,1,1.0), named_stract(‘col1’,’1’,’col2’,1,’clo3’,1.0) |</span><br><span class="line">|   UNION     |  值的数据类型可以是多个被定义的数据类型中的任意一个，这个值通过一个整数（零索引）来标记其为联合类型中的哪个数据类型                                              |                          create_union(1,&#x27;a&#x27;,63)                                    |</span><br><span class="line"></span><br><span class="line">&gt; 数组、映射和结构的文字可以通过函数的形式得到：array()、map()、struct()三个函数都是Hive的内置函数</span><br><span class="line"></span><br><span class="line">#### 3.1.2操作与函数</span><br><span class="line"></span><br><span class="line">Hive提供了普通的SQL操作符，包括：关系操作符（例如等值判断：x=&#x27;a&#x27;;空值判断：x IS NULL; 模式配置 x LIKE &#x27;a%&#x27;），算数操作符（例如加法：x + 1），以及逻辑操作符（例如逻辑或：x OR y））。这些操作符和MySQL的操作符是一样，而和SQL-92不同：||是逻辑操作符，而不是字符串“连接”（concatenation）操作符。在MySQL和Hive中，字符串连接应该用concat函数。  </span><br><span class="line"></span><br><span class="line">##### 1.Hive函数的分类</span><br><span class="line"></span><br><span class="line">1. 数学和统计函数</span><br><span class="line">2. 字符串函数</span><br><span class="line">3. 日期函数（用于操作表示日期的字符串）</span><br><span class="line">4. 条件函数</span><br><span class="line">5. 聚集函数</span><br><span class="line">6. 处理XML（使用xpath函数）和JSON的函数</span><br><span class="line"></span><br><span class="line">&gt; 可以在Hive shell环境中输入SHOW FUNCTIONS以获取函数列表。</span><br><span class="line">&gt;</span><br><span class="line">&gt; DESCRIBE FUNCTION 函数  可以获取函数的的使用帮助</span><br><span class="line"></span><br><span class="line">##### 3.用户定义函数</span><br><span class="line"></span><br><span class="line">你要写的查询语句有时无法轻松（或根本不能）使用Hive提供的内置函数来表示。通过编写`用户自定义函数`[user-defined function,UDF],Hive可以方便地插入用户写的处理代码并在查询中调用它们。</span><br><span class="line"></span><br><span class="line">UDF必须使用Java编写。Hive本身也是使用Java编写的。对于其他的编程语言可以考虑SELECT TRANSFROM查询，可以让数据流经用户定义的脚本。</span><br><span class="line"></span><br><span class="line">Hive有三种UDF：（普通）UDF、用户定义聚集函数（user-defined aggregate function,UDAF）,以及用户定义表生产函数（user-defined table-generating function，UDTF）。它们所接受的的输入和产生的输出的数据行数量不同。</span><br><span class="line"></span><br><span class="line">* UDF操作作用于单个数据行，且产生一个数据行作为输出。大多数函数（例如数学函数和字符串函数）都属于这一类。</span><br><span class="line">* UDAF接受多个输入数据行，并产生一个输出数据行。像COUNT和MAX这样的函数都是聚合函数。</span><br><span class="line">* UDTF操作作用于单行数据行，且产生多个数据行（即一个表）作为输出。</span><br><span class="line"></span><br><span class="line">######  3.1.写UDF</span><br><span class="line"></span><br><span class="line">一个UDF必须满足两个要求</span><br><span class="line"></span><br><span class="line">1. 一个UDF必须是org.apache.hadoop.hive.ql.exec.UDF的子类</span><br><span class="line">2. 一个UDF必须至少实现了evaluate()方法</span><br><span class="line"></span><br><span class="line">&gt; evaluate()方法不是由接口定义的，因为它可接受的参数的个数、它们的数据类型及其返回值的数据类型都是不确定的。Hive会检查UDF，看能否找到和函数调用相匹配的evaluate()方法  </span><br><span class="line"></span><br><span class="line">````java</span><br><span class="line">package com.baizhi;</span><br><span class="line"></span><br><span class="line">import org.apache.hadoop.hive.ql.exec.UDF;</span><br><span class="line"></span><br><span class="line">public class DepUDF extends UDF &#123;</span><br><span class="line">    /*</span><br><span class="line">    	Hive支持在UDF中使用Java的基本类型</span><br><span class="line">    */</span><br><span class="line">    public String evaluate(int value)&#123;</span><br><span class="line">        return &quot;[&quot;+value+&quot;] 部门&quot;;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">````</span><br><span class="line"></span><br><span class="line">为了在Hive中使用UDF，我们需要把编译后的Java类打包成一个JAR文件。在metastore中注册这个函数并使用CREATE FUNCTION 语句为它起名：</span><br><span class="line"></span><br><span class="line">````shell</span><br><span class="line">CREATE FUNCTION DepUDF AS &#x27;com.baizhi.DepUDF&#x27;</span><br><span class="line">USING JAR &#x27;jar包的路径&#x27;;</span><br><span class="line">--------------------------------------------------------------------------------------或者</span><br><span class="line">#仅在Hive会话期间有效，这样创建的函数并没有在metastore中持久化存储</span><br><span class="line">add jar /root/hive-function-1.0.jar;|	hive --auxpath jar包路径#在hive时进行添加</span><br><span class="line">create temporary function dept_fun as &#x27;com.baizhi.DepUDF&#x27;;</span><br><span class="line"></span><br><span class="line">#删除函数的方法 DROP FUNCTION 函数名;</span><br><span class="line">````</span><br><span class="line"></span><br><span class="line">###### 3.2.写UDTF</span><br><span class="line"></span><br><span class="line">````JAVA</span><br><span class="line">package com.baizhi;</span><br><span class="line"></span><br><span class="line">        import org.apache.hadoop.hive.ql.exec.UDFArgumentException;</span><br><span class="line">        import org.apache.hadoop.hive.ql.metadata.HiveException;</span><br><span class="line">        import org.apache.hadoop.hive.ql.udf.generic.GenericUDTF;</span><br><span class="line">        import org.apache.hadoop.hive.serde2.objectinspector.*;</span><br><span class="line">        import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorFactory;</span><br><span class="line"></span><br><span class="line">        import java.util.ArrayList;</span><br><span class="line">        import java.util.Arrays;</span><br><span class="line">        import java.util.List;</span><br><span class="line"></span><br><span class="line">public class UserUDTF extends GenericUDTF &#123;</span><br><span class="line">    public void process(Object[] objects) throws HiveException &#123;</span><br><span class="line">        String value = objects[0].toString();</span><br><span class="line">        String[] tokens = value.split(objects[1].toString());</span><br><span class="line">        forward(Arrays.asList(Integer.parseInt(tokens[0]),tokens[1],Boolean.parseBoolean(tokens[2])));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public void close() throws HiveException &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public StructObjectInspector initialize(StructObjectInspector argOIs) throws UDFArgumentException &#123;</span><br><span class="line">        List&lt;ObjectInspector&gt; objectInspectors = new ArrayList&lt;ObjectInspector&gt;();</span><br><span class="line">        objectInspectors.add(PrimitiveObjectInspectorFactory.javaIntObjectInspector);</span><br><span class="line">        objectInspectors.add(PrimitiveObjectInspectorFactory.javaStringObjectInspector);</span><br><span class="line">        objectInspectors.add(PrimitiveObjectInspectorFactory.javaBooleanObjectInspector);</span><br><span class="line">        List&lt;String&gt; structFieldNames = Arrays.asList(&quot;id&quot;,&quot;name&quot;,&quot;sex&quot;);</span><br><span class="line">        return ObjectInspectorFactory.getStandardStructObjectInspector(structFieldNames, objectInspectors);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">````</span><br><span class="line"></span><br><span class="line">### 3.2.表</span><br><span class="line"></span><br><span class="line">Hive的表在逻辑上由存储的数据和描述表中的数据形式的相关元数据组成。数据一般存放在HDFS中，但也可以存放在其他人很Hadoop文件系统中，包括本地文件系统或S3。</span><br><span class="line"></span><br><span class="line">&gt; 多数据库/模式支持</span><br><span class="line">&gt;</span><br><span class="line">&gt; 很多关系型数据库提供了多个“命名空间”(namespace)的支持。这样，用户和应用就可以被隔离到不同的数据库或模式中。Hive对此也提供了同样的支持，可用的命令包括CREATE DATABASE dbname 以及 DROP DATABASE dbname 这样的语句。可以通过dbname.tablename来完全限定一张表。如果没有明确指明数据库，那么所指的是在default数据库中的表。</span><br><span class="line"></span><br><span class="line">#### 3.2.1.托管表和外部表</span><br><span class="line"></span><br><span class="line">在Hive中创建表的时，默认情况下Hive负责管理数据。意味着Hive把数据移入它的“仓库目录”（warehouse directory）。另一种是创建一个外部表(external table)。这会让Hive到仓库目录以外的位置访问数据。</span><br><span class="line"></span><br><span class="line">* 托管表(managed table) </span><br><span class="line"></span><br><span class="line">  * ```tex</span><br><span class="line">    1^Azhangsan^A17^A15000.0^A1990-12-13^Awatch tv^Bpaly game^Abeijing^Bchina^Alevel^C1^Bdept^C2</span><br><span class="line">    2^Alisi^A18^A10000.0^A1995-12-13^Awatch tv^Bpaly game^Ahanghai^Bchina^Alevel^C1^Bdept^C2 </span><br><span class="line">    ------&gt;data.txt</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ol>
</li>
</ol>
<ul>
<li>```shell<br>#加载数据到托管表是，Hive把数据移到仓库目录<br>CREATE TABLE if not exists t_employee (<br>  id int,<br>  name varchar(32),<br>  age int,<br>  salary double,<br>  birthDay date,<br>  hobbies array<string>,<br>  address struct<a href="street:string,country:string">street:string,country:string</a>,<br>  detail map&lt;string,double&gt;<br>);<br>LOAD DATA INPATH ‘/test/data.txt’ INTO table t_employee;<br>#把文件 hdfs://test/data.txt移动到Hive的t_employee表的仓库目录中，即hdfs://usr/hive/warehouse/t_employee，只有源和目标文件在同一个文件系统中才会移动成功。如果使用了LOCAL关键字，Hive会把本地文件系统的数据复制到Hive的仓库目录（即使它们在一个文件系统中）。在其他所有的情况下，最好把LOAD视为一个移动操作。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">* 外部表(external table)</span><br><span class="line">  * ```tex</span><br><span class="line">    1^Azhangsan^A17^A15000.0^A1990-12-13^Awatch tv^Bpaly game^Abeijing^Bchina^Alevel^C1^Bdept^C2</span><br><span class="line">    2^Alisi^A18^A10000.0^A1995-12-13^Awatch tv^Bpaly game^Ahanghai^Bchina^Alevel^C1^Bdept^C2 </span><br><span class="line">    ------&gt;data.txt</span><br></pre></td></tr></table></figure></li>
<li>```shell<br>#加载数据到托管表是，Hive把数据移到仓库目录<br>CREATE EXTERNAL TABLE if not exists t_employee (<br>  id int,<br>  name varchar(32),<br>  age int,<br>  salary double,<br>  birthDay date,<br>  hobbies array<string>,<br>  address struct<a href="street:string,country:string">street:string,country:string</a>,<br>  detail map&lt;string,double&gt;<br>);LOAD DATA INPATH ‘/test/data.txt’ INTO table t_employee;<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">##### 1.外部表于托管表的区别</span><br><span class="line"></span><br><span class="line">* Hive是否对数据进行管理</span><br><span class="line">  * 托管表Hive对数据进行管理</span><br><span class="line">  * 外部表是由自己对数据的创建和删除</span><br><span class="line">* LOAD关键字的意义不同</span><br><span class="line">  * 托管表是将数据移动到表的仓库目录中</span><br><span class="line">  * 外部表是指明外部数据的文件位置</span><br><span class="line">* DORP的区别</span><br><span class="line">  * 托管表使用DROP的时候表的元数据和数据，都会被删除</span><br><span class="line">  * 外部表只会删除表的元数据</span><br><span class="line"></span><br><span class="line">&gt; 使用场景：如果所有处理都有Hive完成，应该使用托管表。如果要使用Hive和其他工具处理同一个数据，应该使用外部表。需要使用外部表的另一个原因是你想为同一个数据集关联不同的模式。</span><br><span class="line"></span><br><span class="line">#### 3.2.2分区和桶</span><br><span class="line"></span><br><span class="line">Hive把表组织成分区(partition)。这是一种分区列（partition colum，如日期）的值进行粗略划分的机制。使用分区可以加快数据分片（slice）的查询速度。</span><br><span class="line"></span><br><span class="line">表或分区可以进一步分为桶（bucket）。他会为数据提供额外的机构以获得更高效的查询处理。例如，通过根据用户ID来划分桶，我们可以在所有用户集合的随机样本上快速计算基于用户的查询。</span><br><span class="line"></span><br><span class="line">##### 1.分区</span><br><span class="line"></span><br><span class="line">以分区的常用情况为例。考虑日志文件，其中每条记录包含一个时间戳。如果我们根据日期来对它进行分区，那么同一天的记录就会被保存到同一分区中。这样对于限制某个到某些特定日期的查询，它们的处理会变得非常高效。因为它们只需要扫描查询范围内分区中的文件。需要注意的是：使用分区并不会影响大范围查询的执行，我们仍然可以查询跨多个分区的整个数据集。</span><br><span class="line"></span><br><span class="line">一个表可以以多个维度进行分区。例如，在根据日期对日志进行分区以外，我们可能还要进一步根据国家对每个分区进行子分区（subpartition），以加速根据地理位置进行查询。</span><br><span class="line"></span><br><span class="line">分区是在创建表的时候用PARTITIONED BY子句定义的（在创建表之后可以使用ALTER TABLE语句来增加或移除分区）。该子句需要定义列的列表。</span><br><span class="line"></span><br><span class="line">```shell</span><br><span class="line">#日志文件 表记录定义为由时间戳和日志构成：</span><br><span class="line">	#创建表</span><br><span class="line">	CREATE TABLE logs(ts BIGINT,line STRING)</span><br><span class="line">	PARTITIONED BY(dt STRING,country STRING);</span><br><span class="line">	#在加载数据到表的时候，要显示指定分区值：</span><br><span class="line">	LOAD DATE LOCAL INPATH &#x27;/test/logs&#x27; </span><br><span class="line">	INTO TABLE logs</span><br><span class="line">	PARTITION (dt=&#x27;1999-01-23&#x27;,country=&#x27;GB&#x27;)</span><br><span class="line">#在文件系统级别，表目录只是表目录下嵌套的子目录。</span><br><span class="line">#分区情况   /dt-x/country-x结构会生成多个分区目录</span><br><span class="line">SHOW PARTITIONS logs; #展示表中的分区情况</span><br></pre></td></tr></table></figure></li>
</ul>
<blockquote>
<p>PARTITIONS BY 子句中的列定义是表中正是的列，称为分区列（partition column），但是，数据文件并并不含这些列的值，因为它们源于目录名。</p>
</blockquote>
<p>可以在SELECT 语句中以通常的方式使用分区列。Hive会对输入进行修剪，从而只扫描相关的分区。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2020/06/28/Hive/" data-id="cl1z0mgyh000a18vu65xpaegc" data-title="Hive" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2021/06/23/hello-world/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Hello World
        
      </div>
    </a>
  
  
    <a href="/2020/05/28/test/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Conway&#39;s Law</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/07/">July 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/06/">June 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/06/">June 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/05/">May 2020</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2021/07/03/%E4%BA%8C%E6%89%8B%E7%8E%AB%E7%91%B0/">二手玫瑰</a>
          </li>
        
          <li>
            <a href="/2021/07/02/good/">good</a>
          </li>
        
          <li>
            <a href="/2021/07/01/Flying%20Spaghetti%20Monster/">Flying Spaghetti Monster</a>
          </li>
        
          <li>
            <a href="/2021/06/30/Oscar%20Wilde/">Oscar Wilde</a>
          </li>
        
          <li>
            <a href="/2021/06/29/learning/">learning</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2022 Onebirdie<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>